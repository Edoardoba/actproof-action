# EU Artificial Intelligence Act - Overview

## Introduction
The EU Artificial Intelligence Act (AI Act) is the first comprehensive regulatory framework for artificial intelligence systems in the European Union. It was adopted by the European Parliament and entered into force in 2024.

## Objectives
The AI Act aims to:
- Ensure AI systems placed on the EU market are safe and respect fundamental rights
- Enhance legal certainty to facilitate investment and innovation in AI
- Improve governance and enforcement of existing laws applicable to AI systems
- Facilitate the development of a single market for lawful, safe, and trustworthy AI applications

## Risk-Based Classification

### Minimal Risk
AI systems with minimal risk are subject to minimal regulatory requirements. These include:
- AI-enabled video games
- Spam filters
- Inventory management systems

### Limited Risk
Systems with limited risk must comply with transparency obligations:
- Chatbots (users must be informed they are interacting with AI)
- Deepfake generators (content must be clearly labeled)
- Emotion recognition systems

### High Risk
High-risk AI systems must comply with strict requirements before being placed on the market:

**Categories include:**
1. Biometric identification and categorization
2. Management of critical infrastructure
3. Educational and vocational training
4. Employment and worker management
5. Access to essential services (credit scoring, emergency services)
6. Law enforcement
7. Migration and border control
8. Administration of justice and democratic processes

**Requirements for High-Risk Systems:**
- Risk management system (Article 9)
- Data governance and management practices (Article 10)
- Technical documentation (Article 11)
- Record-keeping (Article 12)
- Transparency and provision of information (Article 13)
- Human oversight (Article 14)
- Accuracy, robustness, and cybersecurity (Article 15)

### Prohibited AI Systems
Certain AI practices are completely banned:
- Subliminal manipulation causing harm
- Exploitation of vulnerabilities (age, disability)
- Social scoring by public authorities
- Real-time remote biometric identification in public spaces (with exceptions for law enforcement)

## General-Purpose AI Models (GPAI)

### Standard GPAI Requirements
- Technical documentation
- Information for downstream providers
- Copyright compliance
- Publicly available summaries of training data

### GPAI with Systemic Risk
Additional requirements for models with high-impact capabilities:
- Model evaluation and adversarial testing
- Incident reporting
- Cybersecurity protection
- Energy efficiency reporting

**Systemic Risk Thresholds:**
- Total computational power >10^25 FLOPs
- Other indicators of high-impact capabilities

## Enforcement and Penalties

### Market Surveillance
- Member states must designate market surveillance authorities
- AI Office at EU level for general-purpose AI models
- Coordinated enforcement through European AI Board

### Penalties
Non-compliance can result in fines of:
- €35 million or 7% of global annual turnover (prohibited practices)
- €15 million or 3% of global annual turnover (other obligations)
- €7.5 million or 1.5% of global annual turnover (incorrect information)

## Timeline
- **2024**: Regulation enters into force
- **2025**: Ban on prohibited practices
- **2025-2026**: Requirements for GPAI models apply
- **2026**: Obligations for high-risk systems fully apply
- **2027**: Full applicability of all provisions

## Key Definitions

### AI System
"A machine-based system designed to operate with varying levels of autonomy and that may exhibit adaptiveness after deployment and that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments."

### Provider
"A natural or legal person, public authority, agency or other body that develops an AI system or a general-purpose AI model or that has an AI system or a general-purpose AI model developed and places it on the market or puts the system into service under its own name or trademark, whether for payment or free of charge."

### Deployer
"A natural or legal person, public authority, agency or other body using an AI system under its authority except where the AI system is used in the course of a personal non-professional activity."

## Harmonized Standards
The European Commission may request European standardization organizations to develop harmonized standards. Compliance with these standards creates a presumption of conformity with the AI Act requirements.

**Key standardization areas:**
- Risk management systems
- Data quality and governance
- Technical documentation
- Record-keeping
- Transparency
- Human oversight
- Accuracy and robustness
- Cybersecurity

## References
- Regulation (EU) 2024/1689 of the European Parliament and of the Council
- Official Journal of the European Union, L 2024/1689
- EUR-Lex Document: CELEX:32024R1689
